<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    “Transfer Learning with fast.ai on text classification” |
    
    I hope you find peace</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<script src="/js/pace.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
<main class="content">
  <section class="outer">
  

<article id="post-tlfa" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      “Transfer Learning with fast.ai on text classification”
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2020/01/30/tlfa/" class="article-date">
  <time datetime="2020-01-30T00:04:19.231Z" itemprop="datePublished">2020-01-30</time>
</a>
        
      </div>
    

    
      
    <div class="tocbot"></div>





    

    <div class="article-entry" itemprop="articleBody">
      


      

      
        <p>I would recommende fasi.ai NLP course for every NLP starters: <a href="https://www.fast.ai/2019/07/08/fastai-nlp/" target="_blank" rel="noopener">https://www.fast.ai/2019/07/08/fastai-nlp/</a></p>
<p>This notebook is based on <a href="https://github.com/fastai/course-nlp/blob/master/review-nlp-transfer.ipynb" target="_blank" rel="noopener">https://github.com/fastai/course-nlp/blob/master/review-nlp-transfer.ipynb</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This Python 3 environment comes with many helpful analytics libraries installed</span></span><br><span class="line"><span class="comment"># It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python</span></span><br><span class="line"><span class="comment"># For example, here's several helpful packages to load in </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input data files are available in the "../input/" directory.</span></span><br><span class="line"><span class="comment"># For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dirname, _, filenames <span class="keyword">in</span> os.walk(<span class="string">'/kaggle/input'</span>):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        print(os.path.join(dirname, filename))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Any results you write to the current directory are saved as output.</span></span><br></pre></td></tr></table></figure>

<pre><code>/kaggle/input/nlp-getting-started/train.csv
/kaggle/input/nlp-getting-started/test.csv
/kaggle/input/nlp-getting-started/sample_submission.csv</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastai <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> fastai.text <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">"/kaggle/input/nlp-getting-started"</span></span><br><span class="line"></span><br><span class="line">df_train = pd.read_csv(os.path.join(path,<span class="string">'train.csv'</span>))</span><br><span class="line">df_test = pd.read_csv(os.path.join(path,<span class="string">'test.csv'</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_train.target.plot.hist() <span class="comment"># quite a balance dataset</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faa29d5ce48&gt;</code></pre><p><img src="tlfa_files/tlfa_4_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_test.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just happened a terrible car crash</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Heard about #earthquake is different cities, s...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>there is a forest fire at spot pond, geese are...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Apocalypse lighting. #Spokane #wildfires</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_train.head()</span><br><span class="line"></span><br><span class="line">df_train.drop([<span class="string">'id'</span>,<span class="string">'keyword'</span>,<span class="string">'location'</span>],axis = <span class="number">1</span>,inplace = <span class="literal">True</span>)</span><br><span class="line">df_test_ = df_test.copy().drop([<span class="string">'id'</span>,<span class="string">'keyword'</span>,<span class="string">'location'</span>],axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_test_[<span class="string">'target'</span>] = <span class="number">0</span></span><br><span class="line">df_test_.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Just happened a terrible car crash</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Heard about #earthquake is different cities, s...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>there is a forest fire at spot pond, geese are...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Apocalypse lighting. #Spokane #wildfires</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">valid_ix = np.random.choice(np.arange(len(df_train)),round(len(df_train)*<span class="number">0.2</span>),replace = <span class="literal">False</span>)</span><br><span class="line">train_ix = np.asarray(list(set(np.arange(len(df_train))) - set(valid_ix)))</span><br><span class="line"><span class="keyword">assert</span>(df_train.shape[<span class="number">0</span>] == train_ix.shape[<span class="number">0</span>]+valid_ix.shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bs = <span class="number">32</span></span><br></pre></td></tr></table></figure>

<p>swap the column so that it matches the format in fast.ai, where by default the first column is the label, the second is the text.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_tr = df_train.iloc[train_ix,[<span class="number">1</span>,<span class="number">0</span>]]</span><br><span class="line">df_val = df_train.iloc[valid_ix,[<span class="number">1</span>,<span class="number">0</span>]]</span><br><span class="line">df_te = df_test_.iloc[:,[<span class="number">1</span>,<span class="number">0</span>]]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data_lm = TextLMDataBunch.from_df(path,train_df = df_tr,valid_df = df_val,</span><br><span class="line">                                 )</span><br><span class="line">data_clas = TextClasDataBunch.from_df(path,train_df = df_tr,valid_df = df_val,</span><br><span class="line">                                 vocab=data_lm.train_ds.vocab, bs=bs,</span><br><span class="line">                                     test_df = df_te)</span><br></pre></td></tr></table></figure>






















<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_lm.show_batch()</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>idx</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>orders in xxmaj california xxbos # rockyfire xxmaj update = &gt; xxmaj california xxmaj hwy . 20 closed in both xxunk due to xxmaj lake xxmaj county fire - # xxunk # wildfires xxbos # flood # disaster xxmaj heavy rain causes flash flooding of streets in xxmaj xxunk xxunk xxmaj colorado xxmaj springs areas xxbos i 'm on top of the hill and i can see a fire in</td>
    </tr>
    <tr>
      <td>1</td>
      <td># xxunk https : / / t.co / xxunk xxbos ' xxmaj remembering that you are going to die is the best way i know to avoid the trap of thinking you have something to lose . ' xxup ûò xxmaj steve xxmaj jobs xxbos xxmaj aftershock https : / / t.co / xxunk xxbos xxmaj aftershock back to school kick off was great . i want to thank everyone</td>
    </tr>
    <tr>
      <td>2</td>
      <td>/ / t.co / xxunk xxmaj xxunk xxmaj attack to xxmaj xxunk xxmaj humans http : / / t.co / xxunk xxbos : xxunk : : xxmaj xxunk 3 : : xxmaj xxunk xxmaj annihilation : : http : / / t.co / xxunk via @youtube xxbos xxup u.s xxmaj national xxmaj park xxmaj services xxmaj tonto xxmaj national xxmaj forest : xxmaj stop the xxmaj annihilation of the xxmaj</td>
    </tr>
    <tr>
      <td>3</td>
      <td>t.co / xxunk xxbos xxmaj vote for # xxmaj directioners vs # xxmaj queens in the 5th round of the xxunk # xxunk http : / / t.co / xxmaj xxunk xxbos xxmaj but if you build an army of 100 dogs and their leader is a lion all dogs will fight like a lion . xxbos ' xxmaj show xxmaj me a xxmaj hero ' : xxup tv xxmaj</td>
    </tr>
    <tr>
      <td>4</td>
      <td>xxmaj now xxmaj demand ûïhatchet control?û http : / / t.co / xxunk xxbos xxunk not everyone can see xxunk is xxmaj xxunk that is xxmaj all she can ever xxunk xxunk an attack dog 4 a hate group xxup gop xxbos xxmaj heart disease prevention : xxmaj what about xxunk smoke ? http : / / t.co / xxunk xxbos xxmaj attack on xxmaj titan game on xxup ps</td>
    </tr>
  </tbody>
</table>


<p>Take a look a the tokenizer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x,y = next(iter(data_lm.train_dl))</span><br><span class="line">example = x[:<span class="number">15</span>,:<span class="number">15</span>].cpu()</span><br><span class="line">texts = pd.DataFrame([data_lm.train_ds.vocab.textify(l).split(<span class="string">' '</span>) <span class="keyword">for</span> l <span class="keyword">in</span> example])</span><br><span class="line">texts</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>the</td>
      <td>woods</td>
      <td>...</td>
      <td>xxbos</td>
      <td>xxmaj</td>
      <td>there</td>
      <td>'s</td>
      <td>an</td>
      <td>emergency</td>
      <td>evacuation</td>
      <td>happening</td>
      <td>now</td>
      <td>in</td>
      <td>the</td>
      <td>building</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>for</td>
      <td>making</td>
      <td>it</td>
      <td>possible</td>
      <td>.</td>
      <td>xxmaj</td>
      <td>what</td>
      <td>a</td>
      <td>great</td>
      <td>night</td>
      <td>.</td>
      <td>xxbos</td>
      <td>xxmaj</td>
      <td>people</td>
      <td>who</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>salt</td>
      <td>xxmaj</td>
      <td>river</td>
      <td>xxmaj</td>
      <td>wild</td>
      <td>xxmaj</td>
      <td>horse</td>
      <td>...</td>
      <td>https</td>
      <td>:</td>
      <td>/</td>
      <td>/</td>
      <td>t.co</td>
      <td>/</td>
      <td>xxunk</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>review</td>
      <td>http</td>
      <td>:</td>
      <td>/</td>
      <td>/</td>
      <td>t.co</td>
      <td>/</td>
      <td>xxunk</td>
      <td>http</td>
      <td>:</td>
      <td>/</td>
      <td>/</td>
      <td>t.co</td>
      <td>/</td>
      <td>xxunk</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>xxmaj</td>
      <td>xxunk</td>
      <td>yay</td>
      <td>!</td>
      <td>xxmaj</td>
      <td>ca</td>
      <td>n't</td>
      <td>wait</td>
      <td>for</td>
      <td>2016</td>
      <td>xxbos</td>
      <td>[</td>
      <td>xxunk</td>
      <td>]</td>
      <td>xxmaj</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>5</th>
      <td>wake</td>
      <td>of</td>
      <td>anthrax</td>
      <td>lab</td>
      <td>mishaps</td>
      <td>http</td>
      <td>:</td>
      <td>/</td>
      <td>/</td>
      <td>t.co</td>
      <td>/</td>
      <td>xxunk</td>
      <td>via</td>
      <td>@usatoday</td>
      <td>xxbos</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>6</th>
      <td>i</td>
      <td>was</td>
      <td>bleeding</td>
      <td>n</td>
      <td>shit</td>
      <td>xxbos</td>
      <td>xxunk</td>
      <td>xxmaj</td>
      <td>yes</td>
      <td>i</td>
      <td>'m</td>
      <td>a</td>
      <td>bleeding</td>
      <td>heart</td>
      <td>xxunk</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>7</th>
      <td>'s</td>
      <td>bloody</td>
      <td>awful</td>
      <td>as</td>
      <td>well</td>
      <td>xxunk</td>
      <td>xxx</td>
      <td>xxbos</td>
      <td>i</td>
      <td>ca</td>
      <td>n't</td>
      <td>bloody</td>
      <td>wait</td>
      <td>!</td>
      <td>!</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>8</th>
      <td>problem</td>
      <td>in</td>
      <td>this</td>
      <td>game</td>
      <td>body</td>
      <td>bagging</td>
      <td>niggas</td>
      <td>#</td>
      <td>xxunk</td>
      <td>xxbos</td>
      <td>i</td>
      <td>was</td>
      <td>body</td>
      <td>xxmaj</td>
      <td>bagging</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>9</th>
      <td>forever</td>
      <td>the</td>
      <td>last</td>
      <td>city</td>
      <td>bombed</td>
      <td>with</td>
      <td>a</td>
      <td>nuclear</td>
      <td>weapon</td>
      <td>.</td>
      <td>'</td>
      <td>#</td>
      <td>xxunk</td>
      <td>xxbos</td>
      <td>xxmaj</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>10</th>
      <td>high</td>
      <td>xxmaj</td>
      <td>street</td>
      <td>&amp;</td>
      <td>&amp;</td>
      <td>xxunk</td>
      <td>at</td>
      <td>xxmaj</td>
      <td>xxunk</td>
      <td>xxmaj</td>
      <td>corner</td>
      <td>\n</td>
      <td></td>
      <td>xxmaj</td>
      <td>xxunk</td>
      <td>\n</td>
      <td></td>
    </tr>
    <tr>
      <th>11</th>
      <td>action</td>
      <td>shit</td>
      <td>like</td>
      <td>burning</td>
      <td>buildings</td>
      <td>and</td>
      <td>police</td>
      <td>chases</td>
      <td>not</td>
      <td>some</td>
      <td>weak</td>
      <td>ben</td>
      <td>winston</td>
      <td>shit</td>
      <td>xxbos</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>12</th>
      <td>a</td>
      <td>ground</td>
      <td>war</td>
      <td>were</td>
      <td>in</td>
      <td>the</td>
      <td>xxunk</td>
      <td>of</td>
      <td>millions</td>
      <td>.</td>
      <td>xxunk</td>
      <td>xxbos</td>
      <td>xxmaj</td>
      <td>small</td>
      <td>casualty</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>13</th>
      <td>a</td>
      <td>xxmaj</td>
      <td>cliff</td>
      <td>'</td>
      <td>.</td>
      <td>(</td>
      <td>xxmaj</td>
      <td>real</td>
      <td>xxmaj</td>
      <td>talk</td>
      <td>)</td>
      <td>xxunk</td>
      <td>xxunk</td>
      <td>xxunk</td>
      <td>xxbos</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>14</th>
      <td>moon</td>
      <td>collide</td>
      <td>xxup</td>
      <td>ûó</td>
      <td>oh</td>
      <td>oh</td>
      <td>!</td>
      <td>i</td>
      <td>never</td>
      <td>want</td>
      <td>you</td>
      <td>back</td>
      <td>to</td>
      <td>my</td>
      <td>life</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.is_available()</span><br><span class="line">torch.cuda.current_device()</span><br><span class="line">torch.cuda.set_device(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">opath = <span class="string">'/kaggle/working'</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=<span class="number">0.5</span>,path = opath)</span><br><span class="line">learn.fit_one_cycle(<span class="number">1</span>, <span class="number">1e-2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd</code></pre><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.590240</td>
      <td>3.716148</td>
      <td>0.387078</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.unfreeze()</span><br><span class="line">learn.fit_one_cycle(<span class="number">5</span>, slice(<span class="number">1e-4</span>,<span class="number">1e-2</span>))</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.711925</td>
      <td>3.270358</td>
      <td>0.431002</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.355482</td>
      <td>3.005420</td>
      <td>0.468700</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.968844</td>
      <td>2.932171</td>
      <td>0.481275</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.624769</td>
      <td>2.928576</td>
      <td>0.486384</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2.381097</td>
      <td>2.932316</td>
      <td>0.485913</td>
      <td>00:04</td>
    </tr>
  </tbody>
</table>


<p>Because we fine-tune the model on the tweets about disaster, the result is pretty readable if you start off the sentence with something like</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.predict(<span class="string">"There is an earthquake"</span>, n_words=<span class="number">15</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&apos;There is an earthquake nearby . i think the whole real area is awful . The earthquake could&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.predict(<span class="string">"Huge fire"</span>, n_words=<span class="number">15</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&apos;Huge fire in Northern California http : / / t.co / books http : /&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.predict(<span class="string">"I love my gf"</span>, n_words=<span class="number">15</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&apos;I love my gf the girl love him all that night ? i hated reporting this so bad but&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.save(<span class="string">'ft'</span>)</span><br><span class="line">learn.save_encoder(<span class="string">'ft_enc'</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=<span class="number">0.3</span>)</span><br><span class="line">learn.load_encoder(os.path.join(opath,<span class="string">'models'</span>,<span class="string">'ft_enc'</span>))</span><br></pre></td></tr></table></figure>




<pre><code>RNNLearner(data=TextClasDataBunch;

Train: LabelList (6090 items)
x: TextList
xxbos xxmaj our xxmaj deeds are the xxmaj reason of this # earthquake xxmaj may xxup allah xxmaj xxunk us all,xxbos xxmaj forest fire near xxmaj la xxmaj xxunk xxmaj xxunk . xxmaj canada,xxbos xxmaj all residents asked to &apos; shelter in place &apos; are being xxunk by officers . xxmaj no other evacuation or shelter in place orders are expected,xxbos xxunk people receive # wildfires evacuation orders in xxmaj california,xxbos # rockyfire xxmaj update = &gt; xxmaj california xxmaj hwy . 20 closed in both xxunk due to xxmaj lake xxmaj county fire - # xxunk # wildfires
y: CategoryList
1,1,1,1,1
Path: /kaggle/input/nlp-getting-started;

Valid: LabelList (1523 items)
x: TextList
xxbos xxmaj christian xxmaj attacked by xxmaj muslims at the xxmaj temple xxmaj mount after xxmaj waving xxmaj israeli xxmaj flag via xxmaj pamela xxmaj geller - ... http : / / t.co / xxunk g,xxbos if they kill off xxmaj xxunk i &apos;m rioting # xxmaj emmerdale,xxbos xxunk we got purple xxunk i thought it was a drought,xxbos i &apos;m an emotional wreck watching emmerdale,xxbos xxmaj da xxmaj judge xxmaj gave xxmaj dis xxmaj girl 5 pm xxmaj curfew xxrep 6 ?
y: CategoryList
1,0,1,0,0
Path: /kaggle/input/nlp-getting-started;

Test: LabelList (3263 items)
x: TextList
xxbos xxmaj just happened a terrible car crash,xxbos xxmaj heard about # earthquake is different cities xxunk stay safe everyone .,xxbos there is a forest fire at spot pond xxunk xxunk are fleeing across the street xxunk i can not save them all,xxbos xxmaj apocalypse lighting . # xxmaj xxunk # wildfires,xxbos xxmaj typhoon xxmaj soudelor kills 28 in xxmaj china and xxmaj taiwan
y: EmptyLabelList
,,,,
Path: /kaggle/input/nlp-getting-started, model=SequentialRNN(
  (0): MultiBatchEncoder(
    (module): AWD_LSTM(
      (encoder): Embedding(5952, 400, padding_idx=1)
      (encoder_dp): EmbeddingDropout(
        (emb): Embedding(5952, 400, padding_idx=1)
      )
      (rnns): ModuleList(
        (0): WeightDropout(
          (module): LSTM(400, 1152, batch_first=True)
        )
        (1): WeightDropout(
          (module): LSTM(1152, 1152, batch_first=True)
        )
        (2): WeightDropout(
          (module): LSTM(1152, 400, batch_first=True)
        )
      )
      (input_dp): RNNDropout()
      (hidden_dps): ModuleList(
        (0): RNNDropout()
        (1): RNNDropout()
        (2): RNNDropout()
      )
    )
  )
  (1): PoolingLinearClassifier(
    (layers): Sequential(
      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): Dropout(p=0.12, inplace=False)
      (2): Linear(in_features=1200, out_features=50, bias=True)
      (3): ReLU(inplace=True)
      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): Dropout(p=0.1, inplace=False)
      (6): Linear(in_features=50, out_features=2, bias=True)
    )
  )
), opt_func=functools.partial(&lt;class &apos;torch.optim.adam.Adam&apos;&gt;, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[&lt;function accuracy at 0x7faa73ffc840&gt;], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath(&apos;/kaggle/input/nlp-getting-started&apos;), model_dir=&apos;models&apos;, callback_fns=[functools.partial(&lt;class &apos;fastai.basic_train.Recorder&apos;&gt;, add_time=True, silent=False)], callbacks=[RNNTrainer
learn: RNNLearner(data=TextClasDataBunch;

Train: LabelList (6090 items)
x: TextList
xxbos xxmaj our xxmaj deeds are the xxmaj reason of this # earthquake xxmaj may xxup allah xxmaj xxunk us all,xxbos xxmaj forest fire near xxmaj la xxmaj xxunk xxmaj xxunk . xxmaj canada,xxbos xxmaj all residents asked to &apos; shelter in place &apos; are being xxunk by officers . xxmaj no other evacuation or shelter in place orders are expected,xxbos xxunk people receive # wildfires evacuation orders in xxmaj california,xxbos # rockyfire xxmaj update = &gt; xxmaj california xxmaj hwy . 20 closed in both xxunk due to xxmaj lake xxmaj county fire - # xxunk # wildfires
y: CategoryList
1,1,1,1,1
Path: /kaggle/input/nlp-getting-started;

Valid: LabelList (1523 items)
x: TextList
xxbos xxmaj christian xxmaj attacked by xxmaj muslims at the xxmaj temple xxmaj mount after xxmaj waving xxmaj israeli xxmaj flag via xxmaj pamela xxmaj geller - ... http : / / t.co / xxunk g,xxbos if they kill off xxmaj xxunk i &apos;m rioting # xxmaj emmerdale,xxbos xxunk we got purple xxunk i thought it was a drought,xxbos i &apos;m an emotional wreck watching emmerdale,xxbos xxmaj da xxmaj judge xxmaj gave xxmaj dis xxmaj girl 5 pm xxmaj curfew xxrep 6 ?
y: CategoryList
1,0,1,0,0
Path: /kaggle/input/nlp-getting-started;

Test: LabelList (3263 items)
x: TextList
xxbos xxmaj just happened a terrible car crash,xxbos xxmaj heard about # earthquake is different cities xxunk stay safe everyone .,xxbos there is a forest fire at spot pond xxunk xxunk are fleeing across the street xxunk i can not save them all,xxbos xxmaj apocalypse lighting . # xxmaj xxunk # wildfires,xxbos xxmaj typhoon xxmaj soudelor kills 28 in xxmaj china and xxmaj taiwan
y: EmptyLabelList
,,,,
Path: /kaggle/input/nlp-getting-started, model=SequentialRNN(
  (0): MultiBatchEncoder(
    (module): AWD_LSTM(
      (encoder): Embedding(5952, 400, padding_idx=1)
      (encoder_dp): EmbeddingDropout(
        (emb): Embedding(5952, 400, padding_idx=1)
      )
      (rnns): ModuleList(
        (0): WeightDropout(
          (module): LSTM(400, 1152, batch_first=True)
        )
        (1): WeightDropout(
          (module): LSTM(1152, 1152, batch_first=True)
        )
        (2): WeightDropout(
          (module): LSTM(1152, 400, batch_first=True)
        )
      )
      (input_dp): RNNDropout()
      (hidden_dps): ModuleList(
        (0): RNNDropout()
        (1): RNNDropout()
        (2): RNNDropout()
      )
    )
  )
  (1): PoolingLinearClassifier(
    (layers): Sequential(
      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): Dropout(p=0.12, inplace=False)
      (2): Linear(in_features=1200, out_features=50, bias=True)
      (3): ReLU(inplace=True)
      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): Dropout(p=0.1, inplace=False)
      (6): Linear(in_features=50, out_features=2, bias=True)
    )
  )
), opt_func=functools.partial(&lt;class &apos;torch.optim.adam.Adam&apos;&gt;, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[&lt;function accuracy at 0x7faa73ffc840&gt;], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath(&apos;/kaggle/input/nlp-getting-started&apos;), model_dir=&apos;models&apos;, callback_fns=[functools.partial(&lt;class &apos;fastai.basic_train.Recorder&apos;&gt;, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(
  (0): Embedding(5952, 400, padding_idx=1)
  (1): EmbeddingDropout(
    (emb): Embedding(5952, 400, padding_idx=1)
  )
), Sequential(
  (0): WeightDropout(
    (module): LSTM(400, 1152, batch_first=True)
  )
  (1): RNNDropout()
), Sequential(
  (0): WeightDropout(
    (module): LSTM(1152, 1152, batch_first=True)
  )
  (1): RNNDropout()
), Sequential(
  (0): WeightDropout(
    (module): LSTM(1152, 400, batch_first=True)
  )
  (1): RNNDropout()
), Sequential(
  (0): PoolingLinearClassifier(
    (layers): Sequential(
      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): Dropout(p=0.12, inplace=False)
      (2): Linear(in_features=1200, out_features=50, bias=True)
      (3): ReLU(inplace=True)
      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): Dropout(p=0.1, inplace=False)
      (6): Linear(in_features=50, out_features=2, bias=True)
    )
  )
)], add_time=True, silent=False)
alpha: 2.0
beta: 1.0], layer_groups=[Sequential(
  (0): Embedding(5952, 400, padding_idx=1)
  (1): EmbeddingDropout(
    (emb): Embedding(5952, 400, padding_idx=1)
  )
), Sequential(
  (0): WeightDropout(
    (module): LSTM(400, 1152, batch_first=True)
  )
  (1): RNNDropout()
), Sequential(
  (0): WeightDropout(
    (module): LSTM(1152, 1152, batch_first=True)
  )
  (1): RNNDropout()
), Sequential(
  (0): WeightDropout(
    (module): LSTM(1152, 400, batch_first=True)
  )
  (1): RNNDropout()
), Sequential(
  (0): PoolingLinearClassifier(
    (layers): Sequential(
      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): Dropout(p=0.12, inplace=False)
      (2): Linear(in_features=1200, out_features=50, bias=True)
      (3): ReLU(inplace=True)
      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): Dropout(p=0.1, inplace=False)
      (6): Linear(in_features=50, out_features=2, bias=True)
    )
  )
)], add_time=True, silent=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_clas.show_batch()</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>xxbos _ \n  xxrep 5 ? xxup retweet \n  xxrep 7 ? \n  xxrep 5 ? xxup follow xxup all xxup who xxup rt \n  xxrep 7 ? \n  xxrep 5 ? xxup followback \n  xxrep 7 ? \n  xxrep 5 ? xxup gain xxup with \n  xxrep 7 ? \n  xxrep 5 ? xxup follow ? xxunk # xxup xxunk</td>
      <td>0</td>
    </tr>
    <tr>
      <td>xxbos xxup info xxup r. xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 &amp; &amp; xxup foxtrot 6 xxup navbl . xxup wnd : xxunk / 5 . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup xxunk . xxup tmp : 10 . xxup xxunk : xxunk .</td>
      <td>0</td>
    </tr>
    <tr>
      <td>xxbos xxmaj learn xxmaj how i xxmaj gained xxmaj access xxmaj to xxmaj the xxmaj secrets xxmaj of xxmaj the xxmaj top xxmaj earners &amp; &amp; xxmaj used xxmaj them xxmaj to xxmaj explode xxmaj my xxmaj home xxmaj business xxmaj here : http : / / t.co / xxunk xxmaj please # xxup rt</td>
      <td>0</td>
    </tr>
    <tr>
      <td>xxbos xxmaj xxunk xxmaj hot xxmaj deals # xxunk &gt; &gt; http : / / t.co / xxunk xxunk xxup 27w xxup xxunk xxup xxunk xxup led xxmaj work xxmaj light xxup flood xxmaj lamp xxmaj xxunk xxmaj truck xxup suv xxup utv xxup aû _ http : / / t.co / xxunk</td>
      <td>0</td>
    </tr>
    <tr>
      <td>xxbos xxmaj morgan xxmaj silver xxmaj dollar xxunk p xxup xxunk xxmaj gem xxmaj bu xxup xxunk xxmaj blazing xxup ms xxrep 6 + xxmaj xxunk xxmaj rare xxmaj proof xxmaj like ! - xxmaj full reû _ http : / / t.co / xxunk http : / / t.co / xxunk</td>
      <td>0</td>
    </tr>
  </tbody>
</table>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.fit_one_cycle(<span class="number">1</span>,<span class="number">1e-2</span>)</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.507727</td>
      <td>0.467512</td>
      <td>0.783979</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.unfreeze()</span><br><span class="line">learn.fit_one_cycle(<span class="number">3</span>,slice(<span class="number">1e-4</span>,<span class="number">1e-2</span>))</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.481363</td>
      <td>0.513870</td>
      <td>0.792515</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.448689</td>
      <td>0.434063</td>
      <td>0.810900</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.306059</td>
      <td>0.435390</td>
      <td>0.814839</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>


<h2 id="NB"><a href="#NB" class="headerlink" title="NB"></a>NB</h2><p>By default, <code>get_preds</code> returns <code>probabilities</code> and <code>true_labels</code>, not <code>predicted_labels</code>. So use <code>np.argmax(probs,axis=1)</code> to get the predicted labels</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">valid_probs,valid_y = learn.get_preds(ds_type = DatasetType.Valid,ordered = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>






<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">valid_preds = np.argmax(valid_probs,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy_score(valid_y,valid_preds)</span><br></pre></td></tr></table></figure>




<pre><code>0.81483913328956</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(learn.predict(<span class="string">'Huge fire near the Leceister Square but it is fake'</span>))</span><br><span class="line">learn.predict(<span class="string">'Huge fire near the Leceister Square'</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<pre><code>(Category 1, tensor(1), tensor([0.0470, 0.9530]))





Category 1</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_probs,_ = learn.get_preds(ds_type = DatasetType.Test,ordered = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>






<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_preds = np.argmax(test_probs.numpy(),<span class="number">1</span>)</span><br><span class="line">print(<span class="string">f'<span class="subst">&#123;test_preds.sum()&#125;</span> postives in <span class="subst">&#123;test_preds.shape[<span class="number">0</span>]&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>

<pre><code>1272 postives in 3263</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample_submission = pd.read_csv(os.path.join(path,<span class="string">'sample_submission.csv'</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample_submission[<span class="string">'target'</span>] = test_preds</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample_submission.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample_submission.to_csv(<span class="string">'sub_1.csv'</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/30/tlfa/" data-id="ck5zzbx6e0000nuu0a3v22lry"
         class="article-share-link">Share</a>
      
    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="/2020/01/31/transfer/" class="article-nav-link">
        <strong class="article-nav-caption">Newer</strong>
        <div class="article-nav-title">
          
            transfer
          
        </div>
      </a>
    
    
      <a href="/2020/01/30/article/" class="article-nav-link">
        <strong class="article-nav-caption">Older</strong>
        <div class="article-nav-title">article </div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
    <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 I hope you find peace</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean" target="_blank" rel="noopener">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="I hope you find peace"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>

<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




  
<script src="/js/tocbot.min.js"></script>

  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>



<script src="/js/ocean.js"></script>


</body>
</html>